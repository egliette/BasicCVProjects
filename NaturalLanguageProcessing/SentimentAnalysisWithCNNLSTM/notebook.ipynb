{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tmvjVPUCsm5b"
      },
      "source": [
        "# Download data and install dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5HX4QEA-3nfP",
        "outputId": "4bcd4729-538c-4a04-8264-4d759926fd6c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2022-11-19 06:38:33--  https://docs.google.com/uc?export=download&id=15iOm6l8XrR-J4WUp0OhR2KTel1RAwebL&confirm=t\n",
            "Resolving docs.google.com (docs.google.com)... 172.217.194.100, 172.217.194.101, 172.217.194.102, ...\n",
            "Connecting to docs.google.com (docs.google.com)|172.217.194.100|:443... connected.\n",
            "HTTP request sent, awaiting response... 303 See Other\n",
            "Location: https://doc-0o-5o-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/7ovbhv6und6mq314m8qbhq0o5lhh3nbg/1668839850000/04375464899203764954/*/15iOm6l8XrR-J4WUp0OhR2KTel1RAwebL?e=download&uuid=f6dcceea-42f8-4079-b357-fee141f620d9 [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2022-11-19 06:38:36--  https://doc-0o-5o-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/7ovbhv6und6mq314m8qbhq0o5lhh3nbg/1668839850000/04375464899203764954/*/15iOm6l8XrR-J4WUp0OhR2KTel1RAwebL?e=download&uuid=f6dcceea-42f8-4079-b357-fee141f620d9\n",
            "Resolving doc-0o-5o-docs.googleusercontent.com (doc-0o-5o-docs.googleusercontent.com)... 142.251.12.132, 2404:6800:4003:c11::84\n",
            "Connecting to doc-0o-5o-docs.googleusercontent.com (doc-0o-5o-docs.googleusercontent.com)|142.251.12.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 69449386 (66M) [application/json]\n",
            "Saving to: ‘IMDB.json’\n",
            "\n",
            "IMDB.json           100%[===================>]  66.23M   151MB/s    in 0.4s    \n",
            "\n",
            "2022-11-19 06:38:37 (151 MB/s) - ‘IMDB.json’ saved [69449386/69449386]\n",
            "\n",
            "--2022-11-19 06:38:37--  https://docs.google.com/uc?export=download&id=12kStRhY4tlbjB8TUqQWwJrNkgrkNc_Fx&confirm=t\n",
            "Resolving docs.google.com (docs.google.com)... 172.217.194.100, 172.217.194.101, 172.217.194.102, ...\n",
            "Connecting to docs.google.com (docs.google.com)|172.217.194.100|:443... connected.\n",
            "HTTP request sent, awaiting response... 303 See Other\n",
            "Location: https://doc-04-5o-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/tmr80dcg10ohhr8fqs272r23s2a8hupl/1668839850000/04375464899203764954/*/12kStRhY4tlbjB8TUqQWwJrNkgrkNc_Fx?e=download&uuid=a2970f7e-40f7-40f2-a4df-9551daa880eb [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2022-11-19 06:38:43--  https://doc-04-5o-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/tmr80dcg10ohhr8fqs272r23s2a8hupl/1668839850000/04375464899203764954/*/12kStRhY4tlbjB8TUqQWwJrNkgrkNc_Fx?e=download&uuid=a2970f7e-40f7-40f2-a4df-9551daa880eb\n",
            "Resolving doc-04-5o-docs.googleusercontent.com (doc-04-5o-docs.googleusercontent.com)... 142.251.12.132, 2404:6800:4003:c11::84\n",
            "Connecting to doc-04-5o-docs.googleusercontent.com (doc-04-5o-docs.googleusercontent.com)|142.251.12.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 66212309 (63M) [text/csv]\n",
            "Saving to: ‘IMDB.csv’\n",
            "\n",
            "IMDB.csv            100%[===================>]  63.14M  55.5MB/s    in 1.1s    \n",
            "\n",
            "2022-11-19 06:38:45 (55.5 MB/s) - ‘IMDB.csv’ saved [66212309/66212309]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget \"https://docs.google.com/uc?export=download&id=12kStRhY4tlbjB8TUqQWwJrNkgrkNc_Fx&confirm=t\" -O IMDB.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gWAGMtlF69JS",
        "outputId": "8df43766-0687-45f2-9818-d17b708e2b0a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchtext==0.10.0\n",
            "  Downloading torchtext-0.10.0-cp37-cp37m-manylinux1_x86_64.whl (7.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.6 MB 19.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext==0.10.0) (2.23.0)\n",
            "Collecting torch==1.9.0\n",
            "  Downloading torch-1.9.0-cp37-cp37m-manylinux1_x86_64.whl (831.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 831.4 MB 2.8 kB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext==0.10.0) (4.64.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchtext==0.10.0) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.9.0->torchtext==0.10.0) (4.1.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.10.0) (2022.9.24)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.10.0) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.10.0) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.10.0) (2.10)\n",
            "Installing collected packages: torch, torchtext\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.12.1+cu113\n",
            "    Uninstalling torch-1.12.1+cu113:\n",
            "      Successfully uninstalled torch-1.12.1+cu113\n",
            "  Attempting uninstall: torchtext\n",
            "    Found existing installation: torchtext 0.13.1\n",
            "    Uninstalling torchtext-0.13.1:\n",
            "      Successfully uninstalled torchtext-0.13.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.13.1+cu113 requires torch==1.12.1, but you have torch 1.9.0 which is incompatible.\n",
            "torchaudio 0.12.1+cu113 requires torch==1.12.1, but you have torch 1.9.0 which is incompatible.\u001b[0m\n",
            "Successfully installed torch-1.9.0 torchtext-0.10.0\n"
          ]
        }
      ],
      "source": [
        "# !pip install torchtext==0.10.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DCUkh1vEsubK"
      },
      "source": [
        "# Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7y8rCQRWsjRS"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torchtext.legacy import data\n",
        "from torchtext.legacy import datasets\n",
        "import spacy\n",
        "nlp = spacy.load('en_core_web_sm')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sO6WL0mX--S-"
      },
      "source": [
        "# Declare constants"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "61Cu_jIv_ATd"
      },
      "outputs": [],
      "source": [
        "REVIEW = data.Field(tokenize='spacy',\n",
        "                    tokenizer_language='en_core_web_sm',\n",
        "                    include_lengths=True,\n",
        "                    batch_first = True)\n",
        "SENTIMENT = data.Field(pad_token=None,\n",
        "                       unk_token=None,\n",
        "                       dtype=torch.float)\n",
        "\n",
        "MAX_VOCAB_SIZE = 25_000\n",
        "\n",
        "EMBEDDING_DIM = 100\n",
        "N_FILTERS = 150\n",
        "FILTER_SIZES = [3,4,5]\n",
        "HIDDEN_DIM = 256\n",
        "OUTPUT_DIM = 1\n",
        "N_LAYERS = 2\n",
        "BIDIRECTIONAL = True\n",
        "DROPOUT = 0.5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ipQUEIQ7sxeZ"
      },
      "source": [
        "# Prepare data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ts9In3Ph75if"
      },
      "outputs": [],
      "source": [
        "fields = [(\"review\", REVIEW), (\"sentiment\", SENTIMENT)]\n",
        "full_data = data.TabularDataset(path='IMDB.csv',  \n",
        "                                format='csv',\n",
        "                                fields=fields,\n",
        "                                skip_header=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F-ODaQBCKuzx",
        "outputId": "c51dc055-40d4-4efd-ab68-6c7490737edd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "50000"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(full_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b99OYVrILQPW"
      },
      "outputs": [],
      "source": [
        "train_data, valid_data, test_data = full_data.split(split_ratio=[0.8, 0.1, 0.1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6b413LC4kQ-2",
        "outputId": "735cb819-c5b9-45ff-ea7e-dd2ea813cee9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(40000, 5000, 5000)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(train_data), len(valid_data), len(test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WjMJGf0Emaro",
        "outputId": "11211d25-834d-4cc8-d98b-706a6a389261"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ".vector_cache/glove.6B.zip: 862MB [02:41, 5.35MB/s]                           \n",
            "100%|█████████▉| 399999/400000 [00:17<00:00, 23407.72it/s]\n"
          ]
        }
      ],
      "source": [
        "REVIEW.build_vocab(train_data, \n",
        "                   max_size = MAX_VOCAB_SIZE,\n",
        "                   vectors = \"glove.6B.100d\",\n",
        "                   unk_init = torch.Tensor.normal_)\n",
        "SENTIMENT.build_vocab(train_data)\n",
        "\n",
        "INPUT_DIM = len(REVIEW.vocab)\n",
        "PAD_IDX = REVIEW.vocab.stoi[REVIEW.pad_token]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZoHZpS_snbtq",
        "outputId": "2f342756-0780-4b60-dc62-24fc471d3cce"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(25002, 2)"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(REVIEW.vocab), len(SENTIMENT.vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k5j5_IdWnfnV",
        "outputId": "b9a3af48-2f2d-4b59-b504-f692207ab422"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "defaultdict(None, {'positive': 0, 'negative': 1})"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "SENTIMENT.vocab.stoi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NKGn9Ee4njQ5"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 64\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
        "                                                    (train_data,valid_data,test_data), \n",
        "                                                    batch_size=BATCH_SIZE,\n",
        "                                                    sort_key=lambda x: len(x.review),\n",
        "                                                    sort_within_batch=True,\n",
        "                                                    device=device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "984oks2Vu6h_"
      },
      "source": [
        "# Build the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V-HM1V-7pTH5"
      },
      "outputs": [],
      "source": [
        "class MultiChannelModel(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, n_filters, filter_sizes, hidden_dim, output_dim, n_layers, \n",
        "                 bidirectional, dropout, pad_idx):\n",
        "        \n",
        "        super().__init__()\n",
        "        \n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx = pad_idx)\n",
        "        \n",
        "        self.convs = nn.ModuleList([\n",
        "                                    nn.Conv1d(in_channels = embedding_dim, \n",
        "                                              out_channels = n_filters, \n",
        "                                              kernel_size = fs)\n",
        "                                    for fs in filter_sizes\n",
        "                                    ])\n",
        "\n",
        "        self.rnn = nn.LSTM(embedding_dim, \n",
        "                           hidden_dim, \n",
        "                           num_layers=n_layers, \n",
        "                           bidirectional=bidirectional, \n",
        "                           dropout=dropout,\n",
        "                           batch_first = True)\n",
        "        \n",
        "        self.fc = nn.Linear(len(filter_sizes) * n_filters + hidden_dim * 2, output_dim)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, text, text_lengths):\n",
        "        \n",
        "        #text = [batch size, sent len]\n",
        "        \n",
        "        # CNN ##################################################################\n",
        "\n",
        "        embedded = self.embedding(text)    \n",
        "        #embedded = [batch size, sent len, emb dim]\n",
        "        \n",
        "        embedded = embedded.permute(0, 2, 1)\n",
        "        #embedded = [batch size, emb dim, sent len]\n",
        "        \n",
        "        conved = [F.relu(conv(embedded)) for conv in self.convs]   \n",
        "        #conved_n = [batch size, n_filters, sent len - filter_sizes[n] + 1]\n",
        "        \n",
        "        pooled = [F.max_pool1d(conv, conv.shape[2]).squeeze(2) for conv in conved]\n",
        "        #pooled_n = [batch size, n_filters]\n",
        "        \n",
        "        conv_cat = torch.cat(pooled, dim = 1)\n",
        "        #conv_cat = [batch size, n_filters * len(filter_sizes)]\n",
        "        \n",
        "\n",
        "        # LSTM #################################################################\n",
        "\n",
        "        embedded = self.embedding(text)    \n",
        "        #embedded = [batch size, sent len, emb dim]\n",
        "\n",
        "        #pack sequence\n",
        "        # lengths need to be on CPU!\n",
        "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, \n",
        "                                                            text_lengths.to('cpu'), \n",
        "                                                            batch_first=True)\n",
        "        \n",
        "        packed_output, (hidden, cell) = self.rnn(packed_embedded)\n",
        "        #hidden = [batch size, num layers * num directions, hid dim]\n",
        "        #cell = [batch size, num layers * num directions, hid dim]\n",
        "        \n",
        "        #unpack sequence\n",
        "        output, output_lengths = nn.utils.rnn.pad_packed_sequence(packed_output, \n",
        "                                                                  batch_first=True)\n",
        "        #output = [batch size, sent len, hid dim * num directions]\n",
        "        \n",
        "        #concat the final forward (hidden[-2,:,:]) and backward (hidden[-1,:,:]) hidden layers\n",
        "        hidden_cat = torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1)\n",
        "        #hidden_cat = [batch size, hid dim * num directions]\n",
        "\n",
        "        result = self.dropout(torch.cat((conv_cat, hidden_cat), dim = 1))\n",
        "        #result = [batch size, len(filter sizes) * n filters + hidden dim * 2]\n",
        "            \n",
        "        return self.fc(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dvTw2As8vG1G"
      },
      "outputs": [],
      "source": [
        "model = MultiChannelModel(INPUT_DIM, \n",
        "                          EMBEDDING_DIM, \n",
        "                          N_FILTERS,\n",
        "                          FILTER_SIZES,\n",
        "                          HIDDEN_DIM, \n",
        "                          OUTPUT_DIM, \n",
        "                          N_LAYERS, \n",
        "                          BIDIRECTIONAL, \n",
        "                          DROPOUT, \n",
        "                          PAD_IDX)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X70dag84vPwL",
        "outputId": "d8c9a313-9b83-4917-e947-4327c3fc103b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The model has 4,991,757 trainable parameters\n"
          ]
        }
      ],
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z8qMMF-EAHQ1"
      },
      "source": [
        "## Use pretrained word embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4gOoP-jgvWUs",
        "outputId": "f0572d0a-99d2-48d6-fb0c-e9645fc2cf82"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([25002, 100])\n"
          ]
        }
      ],
      "source": [
        "pretrained_embeddings = REVIEW.vocab.vectors\n",
        "\n",
        "print(pretrained_embeddings.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NigdtubPvXoe",
        "outputId": "3fdf9762-933f-40e8-fa09-a8fe917b053f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[-1.0617e+00,  1.5777e-01,  7.4565e-01,  ...,  3.5641e-03,\n",
              "         -1.4136e+00,  6.6208e-01],\n",
              "        [ 8.1611e-01,  1.2886e+00, -3.2730e+00,  ..., -6.0458e-01,\n",
              "          1.5436e+00,  1.7090e-01],\n",
              "        [-3.8194e-02, -2.4487e-01,  7.2812e-01,  ..., -1.4590e-01,\n",
              "          8.2780e-01,  2.7062e-01],\n",
              "        ...,\n",
              "        [-2.5150e-02,  1.0131e+00, -6.5432e-01,  ...,  1.0351e+00,\n",
              "          3.1442e-01,  1.4225e+00],\n",
              "        [ 2.4607e-04,  1.5502e+00, -2.1343e-02,  ..., -5.4500e-01,\n",
              "         -8.3147e-01, -7.3532e-01],\n",
              "        [-2.5210e+00, -1.0057e-01, -5.4498e-01,  ..., -1.5410e+00,\n",
              "          1.7243e+00,  9.3774e-01]])"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.embedding.weight.data.copy_(pretrained_embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IPMerh5sverR",
        "outputId": "7358df15-d4f7-4f93-b368-345e4385b92f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00],\n",
            "        [-3.8194e-02, -2.4487e-01,  7.2812e-01,  ..., -1.4590e-01,\n",
            "          8.2780e-01,  2.7062e-01],\n",
            "        ...,\n",
            "        [-2.5150e-02,  1.0131e+00, -6.5432e-01,  ...,  1.0351e+00,\n",
            "          3.1442e-01,  1.4225e+00],\n",
            "        [ 2.4607e-04,  1.5502e+00, -2.1343e-02,  ..., -5.4500e-01,\n",
            "         -8.3147e-01, -7.3532e-01],\n",
            "        [-2.5210e+00, -1.0057e-01, -5.4498e-01,  ..., -1.5410e+00,\n",
            "          1.7243e+00,  9.3774e-01]])\n"
          ]
        }
      ],
      "source": [
        "UNK_IDX = REVIEW.vocab.stoi[REVIEW.unk_token]\n",
        "\n",
        "model.embedding.weight.data[UNK_IDX] = torch.zeros(EMBEDDING_DIM)\n",
        "model.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)\n",
        "\n",
        "print(model.embedding.weight.data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v6Jq2t2cATmD"
      },
      "source": [
        "# Create optimzer and loss function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DCF8ZyBDvgrN"
      },
      "outputs": [],
      "source": [
        "optimizer = optim.Adam(model.parameters())\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xEkdBqMOvqhJ"
      },
      "outputs": [],
      "source": [
        "def binary_accuracy(preds, y):\n",
        "    \"\"\"\n",
        "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
        "    \"\"\"\n",
        "\n",
        "    #round predictions to the closest integer\n",
        "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
        "    correct = (rounded_preds == y).float() #convert into float for division \n",
        "    acc = correct.sum() / len(correct)\n",
        "    return acc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-FS-E1vJqQZ2"
      },
      "source": [
        "# Train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jtJ1oHAqvsMJ"
      },
      "outputs": [],
      "source": [
        "def train(model, iterator, optimizer, criterion):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    for batch in iterator:\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        text, text_lengths = batch.review\n",
        "        \n",
        "        predictions = model(text, text_lengths).squeeze(1)\n",
        "        # print(batch.sentiment.squeeze(0).shape)\n",
        "        # print(predictions.shape)\n",
        "        loss = criterion(predictions, batch.sentiment.squeeze(0))\n",
        "        \n",
        "        acc = binary_accuracy(predictions, batch.sentiment.squeeze(0))\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d-SdmsycvtwB"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for batch in iterator:\n",
        "\n",
        "            text, text_lengths = batch.review\n",
        "            \n",
        "            predictions = model(text, text_lengths).squeeze(1)\n",
        "            \n",
        "            loss = criterion(predictions, batch.sentiment.squeeze(0))\n",
        "            \n",
        "            acc = binary_accuracy(predictions, batch.sentiment.squeeze(0))\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "97mrA19Uvvh_"
      },
      "outputs": [],
      "source": [
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dMQtPSfRv1tk",
        "outputId": "14673405-2e85-4c14-9d22-963fd410b175"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:652: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool1d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Epoch Time: 1m 23s\n",
            "\tTrain Loss: 0.495 | Train Acc: 74.71%\n",
            "\t Val. Loss: 0.324 |  Val. Acc: 86.29%\n",
            "Epoch: 02 | Epoch Time: 1m 24s\n",
            "\tTrain Loss: 0.297 | Train Acc: 87.30%\n",
            "\t Val. Loss: 0.281 |  Val. Acc: 88.11%\n",
            "Epoch: 03 | Epoch Time: 1m 22s\n",
            "\tTrain Loss: 0.196 | Train Acc: 92.31%\n",
            "\t Val. Loss: 0.248 |  Val. Acc: 90.21%\n",
            "Epoch: 04 | Epoch Time: 1m 22s\n",
            "\tTrain Loss: 0.143 | Train Acc: 94.69%\n",
            "\t Val. Loss: 0.259 |  Val. Acc: 90.76%\n",
            "Epoch: 05 | Epoch Time: 1m 23s\n",
            "\tTrain Loss: 0.095 | Train Acc: 96.55%\n",
            "\t Val. Loss: 0.291 |  Val. Acc: 90.45%\n"
          ]
        }
      ],
      "source": [
        "N_EPOCHS = 5\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "\n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
        "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
        "    \n",
        "    end_time = time.time()\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'tut2-model.pt')\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MZnLPWHQv2w7",
        "outputId": "cc8e5e78-0b53-40ae-cc89-d14fb503b12d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Loss: 0.243 | Test Acc: 90.49%\n"
          ]
        }
      ],
      "source": [
        "model.load_state_dict(torch.load('tut2-model.pt'))\n",
        "\n",
        "test_loss, test_acc = evaluate(model, test_iterator, criterion)\n",
        "\n",
        "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ycNdsOJx0cC"
      },
      "source": [
        "# Test the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XKKu0kZY_OfD"
      },
      "outputs": [],
      "source": [
        "def predict_sentiment(model, sentence, min_len=5):\n",
        "    model.eval()\n",
        "    tokenized = [tok.text for tok in nlp.tokenizer(sentence)]\n",
        "    text_lengths = torch.Tensor([len(tokenized)])\n",
        "    if len(tokenized) < min_len:\n",
        "        tokenized += ['<pad>'] * (min_len - len(tokenized))\n",
        "    indexed = [REVIEW.vocab.stoi[t] for t in tokenized]\n",
        "    tensor = torch.LongTensor(indexed).to(device)\n",
        "    tensor = tensor.unsqueeze(0)\n",
        "    prediction = torch.sigmoid(model(tensor, text_lengths))\n",
        "    return prediction.item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VtKoSj-2_OuT",
        "outputId": "82587398-ee55-4c2f-c7b2-274a8a939e2b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.9987584352493286"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predict_sentiment(model, \"This film is terrible\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gsZEulp__P6Q",
        "outputId": "040ab53a-33ef-4e12-b3ef-e92c1801d3ba"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.006380683276802301"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predict_sentiment(model, \"This film is great\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "saOFPcbI_XL6",
        "outputId": "bb132ba3-088a-4c1f-e097-362bd980363a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.7619508504867554"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predict_sentiment(model, \"I don't like this film\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1pSaukiunAv9"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.10.7 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.7"
    },
    "vscode": {
      "interpreter": {
        "hash": "356289654fa992607dfe3eb6b371dfdbf25c942ac96138820a3d41d24c520d51"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
