{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from pprint import pprint\n",
    "\n",
    "import tqdm\n",
    "import torch\n",
    "import torchtext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameters and constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_VOCAB_SIZE = 25_000\n",
    "BATCH_SIZE = 64\n",
    "EMBEDDING_DIM = 100\n",
    "HIDDEN_DIM = 256\n",
    "OUTPUT_DIM = 1\n",
    "LEARNING_RATE = 1e-3\n",
    "N_EPOCHS = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Device configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMDb dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ” Download and installation successful\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_sm -Uqq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1234\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "TEXT = torchtext.legacy.data.Field(tokenize=\"spacy\", tokenizer_language=\"en_core_web_sm\")\n",
    "LABEL = torchtext.legacy.data.LabelField(dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = torchtext.legacy.datasets.IMDB.splits(TEXT, LABEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'label': 'neg',\n",
      " 'text': ['This',\n",
      "          'movie',\n",
      "          'has',\n",
      "          'got',\n",
      "          'to',\n",
      "          'be',\n",
      "          'one',\n",
      "          'of',\n",
      "          'the',\n",
      "          'worst',\n",
      "          'I',\n",
      "          'have',\n",
      "          'ever',\n",
      "          'seen',\n",
      "          'make',\n",
      "          'it',\n",
      "          'to',\n",
      "          'DVD',\n",
      "          '!',\n",
      "          '!',\n",
      "          '!',\n",
      "          'The',\n",
      "          'story',\n",
      "          'line',\n",
      "          'might',\n",
      "          'have',\n",
      "          'clicked',\n",
      "          'if',\n",
      "          'the',\n",
      "          'film',\n",
      "          'had',\n",
      "          'more',\n",
      "          'funding',\n",
      "          'and',\n",
      "          'writers',\n",
      "          'that',\n",
      "          'would',\n",
      "          'have',\n",
      "          'cut',\n",
      "          'the',\n",
      "          'nonsense',\n",
      "          'and',\n",
      "          'sickly',\n",
      "          'scenes',\n",
      "          'that',\n",
      "          'I',\n",
      "          'highly',\n",
      "          'caution',\n",
      "          'parents',\n",
      "          'on',\n",
      "          '....',\n",
      "          'But',\n",
      "          'the',\n",
      "          'story',\n",
      "          'line',\n",
      "          'is',\n",
      "          'like',\n",
      "          'a',\n",
      "          'loose',\n",
      "          'cannon',\n",
      "          '.',\n",
      "          'If',\n",
      "          'there',\n",
      "          'was',\n",
      "          'such',\n",
      "          'a',\n",
      "          'thing',\n",
      "          'as',\n",
      "          'a',\n",
      "          'drive',\n",
      "          'thru',\n",
      "          'movie',\n",
      "          'maker',\n",
      "          '-',\n",
      "          'this',\n",
      "          'one',\n",
      "          'would',\n",
      "          'have',\n",
      "          'sprung',\n",
      "          'from',\n",
      "          'that',\n",
      "          '.',\n",
      "          'It',\n",
      "          'reminded',\n",
      "          'me',\n",
      "          'a',\n",
      "          'lot',\n",
      "          'of',\n",
      "          'the',\n",
      "          'quickie',\n",
      "          'films',\n",
      "          'that',\n",
      "          'were',\n",
      "          'put',\n",
      "          'out',\n",
      "          'in',\n",
      "          'the',\n",
      "          '1960',\n",
      "          \"'s\",\n",
      "          ',',\n",
      "          'poor',\n",
      "          'script',\n",
      "          'writing',\n",
      "          'and',\n",
      "          'filming',\n",
      "          '.',\n",
      "          '<',\n",
      "          'br',\n",
      "          '/><br',\n",
      "          '/>The',\n",
      "          'only',\n",
      "          'sensible',\n",
      "          'characters',\n",
      "          'in',\n",
      "          'the',\n",
      "          'whole',\n",
      "          'movie',\n",
      "          'was',\n",
      "          'the',\n",
      "          'bartender',\n",
      "          'and',\n",
      "          'beaver',\n",
      "          '.',\n",
      "          'The',\n",
      "          'rest',\n",
      "          'of',\n",
      "          'the',\n",
      "          'film',\n",
      "          ',',\n",
      "          'could',\n",
      "          'have',\n",
      "          'easily',\n",
      "          'been',\n",
      "          'made',\n",
      "          'by',\n",
      "          'middle',\n",
      "          'school',\n",
      "          'children',\n",
      "          '.',\n",
      "          'I',\n",
      "          'give',\n",
      "          'this',\n",
      "          'film',\n",
      "          'a',\n",
      "          'rating',\n",
      "          'of',\n",
      "          '1',\n",
      "          'as',\n",
      "          'it',\n",
      "          'is',\n",
      "          'truly',\n",
      "          'awful',\n",
      "          'and',\n",
      "          'left',\n",
      "          'my',\n",
      "          'entire',\n",
      "          'family',\n",
      "          'with',\n",
      "          'a',\n",
      "          'sense',\n",
      "          'of',\n",
      "          'being',\n",
      "          'cheated',\n",
      "          '.',\n",
      "          'My',\n",
      "          'advice',\n",
      "          '-',\n",
      "          \"Don't\",\n",
      "          'Watch',\n",
      "          'It',\n",
      "          '!',\n",
      "          '!',\n",
      "          '!']}\n"
     ]
    }
   ],
   "source": [
    "pprint(vars(train_data.examples[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, valid_data = train_data.split(random_state=random.seed(SEED))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 17500\n",
      "Number of validation examples: 7500\n",
      "Number of testing data: 25000\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of training examples: {len(train_data)}\")\n",
    "print(f\"Number of validation examples: {len(valid_data)}\")\n",
    "print(f\"Number of testing data: {len(test_data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT.build_vocab(train_data, max_size=MAX_VOCAB_SIZE)\n",
    "LABEL.build_vocab(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 25002\n",
      "Unique tokens in LABEL vocabulary: 2\n"
     ]
    }
   ],
   "source": [
    "print(f\"Unique tokens in TEXT vocabulary: {len(TEXT.vocab)}\")\n",
    "print(f\"Unique tokens in LABEL vocabulary: {len(LABEL.vocab)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 203566), (',', 192495), ('.', 165544), ('and', 109443), ('a', 109116), ('of', 100702), ('to', 93766), ('is', 76328), ('in', 61255), ('I', 54004)]\n",
      "['<unk>', '<pad>', 'the', ',', '.', 'and', 'a', 'of', 'to', 'is']\n"
     ]
    }
   ],
   "source": [
    "print(TEXT.vocab.freqs.most_common(10))\n",
    "print(TEXT.vocab.itos[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(None, {'neg': 0, 'pos': 1})\n"
     ]
    }
   ],
   "source": [
    "print(LABEL.vocab.stoi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create iterators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iterator, valid_iterator, test_iterator = torchtext.legacy.data.BucketIterator.splits(\n",
    "                                                    (train_data, valid_data, test_data),\n",
    "                                                    batch_size=BATCH_SIZE,\n",
    "                                                    device=device\n",
    "                                                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_len, embedding_dim, hidden_dim, output_dim):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embedding = torch.nn.Embedding(vocab_len, embedding_dim)\n",
    "        self.rnn = torch.nn.RNN(embedding_dim, hidden_dim)\n",
    "        self.fc = torch.nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, text):\n",
    "        \"\"\"\n",
    "        @params text list(int): with shape [sent_len, batch_size]\n",
    "        \"\"\"\n",
    "\n",
    "        embedded = self.embedding(text)\n",
    "        # embedded shape: [sent_len, batch_size, embedding_dim]\n",
    "\n",
    "        output, hidden = self.rnn(embedded)\n",
    "        # output shape: [sent_len, batch_size, hidden_dim]\n",
    "        # hidden shape: [1, batch_size, hidden_dim]\n",
    "\n",
    "        assert torch.equal(output[-1,:,:], hidden.squeeze(0))\n",
    "\n",
    "        return self.fc(hidden.squeeze(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_len = len(TEXT.vocab)\n",
    "model = RNN(vocab_len, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 2,592,105 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameter(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"The model has {count_parameter(model):,} trainable parameters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_accuracy(preds, y):\n",
    "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
    "    correct = (rounded_preds == y).sum().float()\n",
    "    acc = correct / len(y)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion, tepoch):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for batch in iterator:\n",
    "        tepoch.update(1)\n",
    "        predictions = model(batch.text).squeeze(1)\n",
    "        loss = criterion(predictions, batch.label)\n",
    "        acc = binary_accuracy(predictions, batch.label)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        tepoch.set_postfix(train_loss=epoch_loss/len(iterator),\n",
    "                            train_accuracy=epoch_acc/len(iterator))\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in iterator:\n",
    "            predictions = model(batch.text).squeeze(1)\n",
    "            loss = criterion(predictions, batch.label)\n",
    "            acc = binary_accuracy(predictions, batch.label)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 274/274 [11:03<00:00,  2.42s/batch, train_accuracy=0.502, train_loss=0.693, valid_accuracy=0.487, valid_loss=0.695]\n",
      "Epoch 2:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 243/274 [10:00<01:12,  2.33s/batch, train_accuracy=0.444, train_loss=0.612]  "
     ]
    }
   ],
   "source": [
    "best_valid_loss = float(\"inf\")\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    tepoch = tqdm.tqdm(train_iterator, unit=\"batch\", leave=True, position=0)\n",
    "    tepoch.set_description(f\"Epoch {epoch+1}\")\n",
    "\n",
    "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion, tepoch)\n",
    "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
    "\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), \"best_model.pt\")\n",
    "        \n",
    "    tepoch.set_postfix(train_loss=train_loss, train_accuracy=train_acc,\n",
    "                       valid_loss=valid_loss, valid_accuracy=valid_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.689 | Test Acc: 54.97%\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"save/best_model.pt\"))\n",
    "\n",
    "test_loss, test_acc = evaluate(model, test_iterator, criterion)\n",
    "\n",
    "print(f\"Test loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dfdf42a4740e8948dedf252b210f893ba6a122117aec80320a945456e1215ce7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
